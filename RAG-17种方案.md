
## Simple RAG

基础假设:通过简单的文本分块和相似度匹配就能找到相关内容

	
	# 原始文本示例：
	"""
	人工智能（AI）技术在现代社会中扮演着越来越重要的角色。从医疗诊断到自动驾驶，从金融分析到教育辅助，AI的应用无处不在。然而，AI系统对大规模数据集的依赖也带来了一系列挑战。一方面，海量数据使得AI模型能够学习更丰富的特征，提供更准确的预测；另一方面，这些数据中可能包含偏见和不平等，如果不加处理，AI系统可能会放大这些社会问题。因此，在开发AI系统时，我们需要在数据量和数据质量之间找到平衡点，确保AI的发展既高效又公平。
	"""
	
	# 按句子拆:
	chunk_1 = """
	人工智能（AI）技术在现代社会中扮演着越来越重要的角色。
	"""
	chunk_2 = """
	从医疗诊断到自动驾驶，从金融分析到教育辅助，AI的应用无处不在。然而，AI系统对大规模数据集的依赖也带来了一系列挑战。
	"""
	chunk_3 = """
	然而，AI系统对大规模数据集的依赖也带来了一系列挑战。一方面，海量数据使得AI模型能够学习更丰富的特征，提供更准确的预测；

	.....
	"""

	# 查询示例：
	query = "AI系统对大规模数据集的依赖会带来哪些问题？"
	
	# 系统会找到最相关的文本块，然后生成回答：
	"""
	AI系统对大规模数据集的依赖会带来以下问题：
	1. 数据偏见：海量数据中可能包含社会偏见和不平等，如果不加处理，AI系统可能会放大这些偏见
	2. 数据质量与数量的平衡：需要在数据量和数据质量之间找到平衡点
	3. 公平性挑战：需要确保AI系统在提供高效服务的同时不会加剧社会不平等
	"""

得分:0.3
## Semantic Chunking

假设:基于语义的分块比固定大小分块更有效,能保持语义完整性

chunk_1与chunk_2计算相似度,比较接近,所以进行合并.

	
	# 按句子拆:
	chunk_1 = """
	人工智能（AI）技术在现代社会中扮演着越来越重要的角色。从医疗诊断到自动驾驶，从金融分析到教育辅助，AI的应用无处不在。然而，AI系统对大规模数据集的依赖也带来了一系列挑战。
	"""
	chunk_2= """
	然而，AI系统对大规模数据集的依赖也带来了一系列挑战。一方面，海量数据使得AI模型能够学习更丰富的特征，提供更准确的预测；

	.....
	"""
得分:0.2

## Context Enriched Retrieval

虽然上面的语意信息集中了，但是仍然缺少上下文的状况.

假设:检索chunk时需要考虑其周围的上下文,单个chunk可能缺少完整信息.

还是按照第一个固定分块或者按句子的拆分方式进行分块，通过相似度查找时。将相邻的块返回。

比如查询的时候,返回给模型更多的上下文(当前块的前后窗口)

比如找到了chunk2. 返回chunk1+chunk2+chunk3

得分:0.6

## Contextual Chunk Headers

假设:为每个chunk添加描述性标题可以提供更好的检索线索

	# 按句子拆:
	chunk_1 = """
	人工智能（AI）技术在现代社会中扮演着越来越重要的角色。
	"""
	  head_1= "AI是个重要的角色"
	  
	chunk_2 = """
	从医疗诊断到自动驾驶，从金融分析到教育辅助，AI的应用无处不在。然而，AI系统对大规模数据集的依赖也带来了一系列挑战。
	"""
	 head_2= "xxx"
	  
	chunk_3 = """
	然而，AI系统对大规模数据集的依赖也带来了一系列挑战。一方面，海量数据使得AI模型能够学习更丰富的特征，提供更准确的预测；
	 head_3= "xxx"
	  
	.....
	"""

然后chunk和head都进行embedding入库.
查询时候,对embedding(chunk)+embedding(head)/2 进行返回.

得分:0.5

## Document Augmentation

假设:从文本生成问题作为额外检索入口可以提高匹配准确度


	# 文本块1
	chunk_1 = """
	人工智能（AI）技术在现代社会中扮演着越来越重要的角色。
	"""
	
	问题1：为什么人工智能技术在现代社会中变得越来越重要？
	问题2：人工智能技术如何改变了我们的日常生活？
	问题3：人工智能技术对社会发展带来了哪些机遇和挑战？
	
	# 文本块2
	chunk_2 = """
	从医疗诊断到自动驾驶，从金融分析到教育辅助，AI的应用无处不在。然而，AI系统对大规模数据集的依赖也带来了一系列挑战。
	"""
	
	问题1：AI在医疗、交通、金融和教育等领域分别带来了哪些具体改变？
	问题2：为什么AI系统需要依赖大规模数据集？
	问题3：AI系统依赖大规模数据集可能带来哪些具体挑战？
	
	# 文本块3
	chunk_3 = """
	然而，AI系统对大规模数据集的依赖也带来了一系列挑战。一方面，海量数据使得AI模型能够学习更丰富的特征，提供更准确的预测；
	"""
	
	问题1：海量数据如何帮助AI模型提升预测准确性？
	问题2：AI模型从海量数据中学习特征的过程是怎样的？
	问题3：除了提升预测准确性，海量数据对AI模型还有哪些其他影响？
	

存储embedding(问题)和chunk,都存储到向量库的一个列中.

1. 检索过程：
- 将用户查询转换为向量
- 在向量库中搜索最相似的内容
- 返回的内容可能是文本块或问题

2. 结果处理：
- 如果是文本块：直接添加到结果集
- 如果是问题：找到问题对应的文本块，添加到结果集
- 使用set避免重复添加相同的文本块

得分:0.8

## Query Transformation

假设:用户的原始查询可能不是最优的检索形式,需要转换和扩展

查询示例：
	query = "AI系统对大规模数据集的依赖会带来哪些问题？"

| 重写方式  | 系统提示词                                                 | 用户提示词                                                                                                                                                                     |
| ----- | ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 查询重写  | 你是一个专门改进搜索查询的AI助手。你的任务是将用户查询重写得更加具体、详细，以便检索到相关信息。     | 请将以下查询重写得更加具体和详细。包含可能有助于检索准确信息的相关术语和概念。<br><br>改写的查询：人工智能系统在处理和分析大规模数据集时可能面临的具体挑战和问题,包括数据质量、存储成本、隐私安全、计算资源消耗以及模型训练效率等方面的影响                                                |
| 回溯提示  | 你是一个专门研究搜索策略的AI助手。你的任务是生成更广泛、更通用的查询版本，以检索相关的背景信息。     | 请生成以下查询的更广泛、更通用的版本，以帮助检索有用的背景信息。<br><br>改写的查询：人工智能系统在数据驱动决策过程中的基础性挑战和限制,包括数据获取、处理、存储和利用等各个环节可能遇到的问题                                                                       |
| 子查询分解 | 你是一个专门分解复杂问题的AI助手。你的任务是将复杂查询分解成更简单的子问题，这些子问题共同回答原始查询。 | 请将以下复杂查询分解成{子查询数量}个更简单的子查询。每个子查询应该关注原始问题的不同方面。<br><br>改写的查询:<br>- 大规模数据集对AI系统的存储和计算资源要求是什么?<br>- 数据质量和隐私保护方面存在哪些潜在风险?<br>- 模型训练和部署过程中可能遇到哪些效率问题?<br>- 如何平衡数据规模与系统性能之间的关系? |
得分:0.5

## Reranker

假设:初始检索结果需要二次排序以提高最相关内容的排名

因为:相似不等于相关
	
	查询: "苹果手机的价格是多少？"
	文档1: "苹果公司最新发布的iPhone 15 Pro Max起售价为999美元。"
	文档2: "苹果是一种常见的水果，富含维生素C。"
	文档3: "苹果公司CEO库克宣布新一代iPhone将于下月发布。
	
	- 然后使用 LLM 对每个文档进行相关性评分：
	- 文档1: 9分（直接回答了价格问题）
	- 文档3: 6分（提到了iPhone但没有价格信息）
	- 文档2: 2分（完全不相关）

查询方案:多查出来相似度比较高的数据, 然后让rerank模型进行相关度排序去相关度最高的数据.

得分:0.7

## RSE

假设:相关信息可能分布在连续的文本段落中,而不是离散的chunk

RSE整个流程是:  
	1.将所有数据进行固定切分,存储到向量库  
	2.过滤出相似度较高的片段  
	3.根据较高的片段进行一个上下文(主要是向下寻找)连续片段的查找(上下文窗口)  
	4.在进行片段的相似度的总和的阈值筛选  
	5.最终将数据进行返回
	
案例:
	原始文档：
	[Chunk1][Chunk2][Chunk3][Chunk4][Chunk5][Chunk6][Chunk7][Chunk8]
	
	1. 相似度过滤后：
	[0.8][0.7][0.2][0.1][0.6][0.5][0.1][0.2]
	  ↑     ↑              ↑     ↑
	 高相关  高相关        高相关  高相关
	
	2. 上下文窗口查找：(假设窗口2)
	[0.8][0.7][0.2][0.1][0.6][0.5][0.1][0.2]
	  └─────┘             └─────┘
	  片段1                  片段2
	      └─────┘     └─────┘  └─────┘
		  片段3         片段4       片段5
	
	3. 片段总值计算：
	片段1: 0.8 + 0.7 = 1.5
	片段2: 0.6 + 0.5 = 1.1
	片段3: 0.7 + 0.2 = 0.9
	片段4: 0.1 + 0.6 = 0.7
	片段5: 0.5 + 0.1 = 0.6
	
	4. 阈值筛选（假设阈值为1.0）：
	保留片段1和片段2（都大于阈值）
	
	5. 最终返回：
	"Chunk1 Chunk2" 和 "Chunk5 Chunk6"
得分:0.8

## Contextual Compression

假设:检索的内容中可能包含无关信息,需要压缩提炼

做法: 获取更多的chunk,然后压缩它,过滤只和query相关的内容,再给到LLM

压缩方法也是使用大模型,提示词如下:
	
	system_prompt = """你是一个专业的信息过滤专家。
	你的任务是分析文档片段,仅提取与用户查询直接相关的句子或段落。删除所有无关内容。
	
	你的输出应该:
	1. 仅包含有助于回答查询的文本
	2. 保持相关句子的原始措辞(不要改写)
	3. 保持文本的原始顺序
	4. 包含所有相关内容,即使看起来有些冗余
	5. 排除所有与查询无关的文本
	
	请以纯文本形式输出,不要添加任何额外注释。"""

得分:0.75


## Feedback Loop

假设:系统可以从用户反馈中学习,持续改进检索质量

因为:你现在数据都是静态的,没有反馈.
	
	一个完整的例子:
	
	1. 初始查询场景
	```
	用户查询: "什么是神经网络?"
	系统检索到3个文档:
	- 文档A: 相似度0.8 (神经网络基础概念)
	- 文档B: 相似度0.6 (深度学习介绍)
	- 文档C: 相似度0.5 (机器学习概述)
	```
	
	1. 系统生成回答
	```
	基于文档A生成回答:
	"神经网络是一种模仿生物神经系统的计算模型..."
	```
	
	2. 用户提供反馈
	```
	相关性评分: 4分 (1-5分)
	质量评分: 5分 (1-5分)
	评论: "解释很清晰,但可以加入更多技术细节"
	```
	
	3. 反馈数据存储
	```json
	{
	    "query": "什么是神经网络?",
	    "response": "神经网络是一种模仿生物神经系统的计算模型...",
	    "relevance": 4,
	    "quality": 5,
	    "comments": "解释很清晰,但可以加入更多技术细节",
	    "timestamp": "2024-03-20T10:30:00"
	}
	```
		备注:使用大模型判断那条chunk对当前问题的相关度高,调整相对应的chunk权重
	
	4. 后续查询优化
	```
	新用户查询: "神经网络的基本原理是什么?"
	
	系统检索到相同文档:
	- 文档A: 原始相似度0.8 -> 调整后0.96 (0.8 × 1.2)
	- 文档B: 原始相似度0.6 -> 保持0.6 (无反馈)
	- 文档C: 原始相似度0.5 -> 保持0.5 (无反馈)
	
	最终排序:
	1. 文档A (调整后0.96)
	2. 文档B (0.6)
	3. 文档C (0.5)
	```
	
	4. 反馈循环效果
	- 文档A因为历史好评被提升排名
	- 更可能被用于生成回答
	- 形成正向反馈循环
	
	1. 数据流转过程
	```
	用户查询 -> 检索文档 -> 生成回答 -> 收集反馈 -> 存储反馈 -> 优化后续检索
	```
	
	2. 实际效果
	- 高质量文档更容易被检索到
	- 回答质量逐步提升
	- 系统性能持续改进
	
	这个例子展示了:
	- 完整的反馈收集过程
	- 反馈数据的存储格式
	- 分数调整的具体计算
	- 排序优化的实际效果
	
	通过这个循环机制:
	- 系统学习用户偏好
	- 优化检索质量
	- 提升回答准确性
	- 改善用户体验


得分:0.7(备注: 这个得分并不准, 因为随着时间推移, 会越来越 )

## Adaptive RAG

假设:不同类型的查询需要不同的检索策略

根据不同的场景细化检索的方式和检索的库.

得分:0.86

## Self RAG

假设:模型可以过滤和问题相关的检索结果,减少噪音数据,用相关性高的片段进行回答

![[Pasted image 20250507165555.png]]

当一个用户问题过来的时候，先判断是否需要检索，如果不需要检索的话就直接回答，如果需要检索的话，去响亮谷里边检索 k 个片段，将拿到的 k 个片段的注意进行相关性评估。这块的我就记得苹果之后只保留相关性比较大的这些片段，最终生了答案

得分:0.6


## Knowledge Graph

假设:信息之间存在关联关系,图结构可以更好地表达这些关系
但是: 构建有效的图谱成本是真高,一定要在于要研究透概念之间的关系的场景下使用.

![[Pasted image 20250507170252.png]]

得分:0.78

## Hierarchical Indices

假设:通过层次化的索引结构可以平衡检索的精确度和上下文


越小的块检索的越准确，越大的块检索的越不准，所以我们可以先把数据切成更小的块，然后进行 summary，让它变得更小，这样的话就检索到了更相关的大块。我们再从大块的内容中进行小块的检索，这样的话我们筛选的信息就更精准了。

![[Pasted image 20250507175801.png]]

得分: 0.84

## HyDE

假设:生成假设性的答案文档可以帮助找到更相关的内容
问题是: 语义的方向不一定是对的. 所以不一定准.
![[Pasted image 20250507180301.png]]

得分:0.5

## Fusion

假设:结合多种检索方法(如向量检索和关键词检索)可以互补优势

- 语义检索能找“意思相近但表达不同”的内容。
- 关键词检索能找“关键词完全命中”的内容。
- 两者结合，极大减少“漏检”。

	### 用户Query
>	 “如何预防感冒？”
	---
	### 语义检索召回的内容（相似但不相关）
	召回内容A：
	“保持良好的作息和饮食习惯有助于增强免疫力，预防疾病。”
	召回内容B（相似但不相关）：
	“预防新冠病毒的方法包括佩戴口罩、勤洗手和保持社交距离。”

得分:0.83

## CRAG

C是指Corrective:纠错的过程


![[Pasted image 20250507181339.png]]

得分:0.824

## 总结

| RAG技术                      | 核心假设/改进思路.                             | 评分    | 实现简易程度 | 理由                            |
| -------------------------- | -------------------------------------- | ----- | ------ | ----------------------------- |
| Simple RAG                 | 基础假设:通过简单的文本分块和相似度匹配就能找到相关内容           | 0.3   | 1      | 只需分块+向量检索，最基础，几乎所有RAG入门方案     |
| Semantic Chunking          | 假设:基于语义的分块比固定大小分块更有效,能保持语义完整性          | 0.2   | 2      | 需用句法/语义分句，稍复杂但主流NLP工具可实现      |
| Context Enriched Retrieval | 假设:检索chunk时需要考虑其周围的上下文,单个chunk可能缺少完整信息 | 0.6   | 2      | 检索时多取前后chunk，拼接即可，逻辑简单        |
| Contextual Chunk Headers   | 假设:为每个chunk添加描述性标题可以提供更好的检索线索          | 0.5   | 2      | 需自动生成标题，稍有工程量，但实现难度不高         |
| Document Augmentation      | 假设:从文本生成问题作为额外检索入口可以提高匹配准确度            | 0.8   | 3      | 需用LLM批量生成问题，数据处理和存储更复杂        |
| Query Transformation       | 假设:用户的原始查询可能不是最优的检索形式,需要转换和扩展          | 0.5   | 3      | 需用LLM或规则对query做多种变换，需调优       |
| Reranker                   | 假设:初始检索结果需要二次排序以提高最相关内容的排名             | 0.7   | 3      | 需引入额外排序模型或LLM，工程复杂度提升         |
| RSE                        | 假设:相关信息可能分布在连续的文本段落中,而不是离散的chunk       | 0.8   | 3      | 需实现连续片段的相关性聚合，逻辑比普通检索复杂       |
| Contextual Compression     | 假设:检索的内容中可能包含无关信息,需要压缩提炼               | 0.75  | 3      | 需用LLM或规则对检索内容做摘要/压缩，需调优       |
| Feedback Loop              | 假设:系统可以从用户反馈中学习,持续改进检索质量               | 0.7   | 4      | 需设计反馈收集、存储、利用机制，涉及持续学习        |
| Adaptive RAG               | 假设:不同类型的查询需要不同的检索策略                    | 0.862 | 4      | 需实现query分类和多策略切换，系统性工程        |
| Self RAG                   | 假设:系统应该能够反思和评估是否需要检索以及过滤和问题相关的检索结果     | 0.6   | 5      | 需实现自反思、动态决策，涉及复杂推理和流程         |
| Knowledge Graph            | 假设:信息之间存在关联关系,图结构可以更好地表达这些关系           | 0.78  | 5      | 需抽取实体关系、构建图谱、图检索，NLP+图数据库     |
| Hierarchical Indices       | 假设:通过层次化的索引结构可以平衡检索的精确度和上下文            | 0.84  | 4      | 需实现多层索引、分层检索，数据结构和检索逻辑复杂      |
| HyDE                       | 假设:生成假设性的答案文档可以帮助找到更相关的内容              | 0.5   | 4      | 需用LLM生成假设文档并向量化，流程较新且需调优      |
| Fusion                     | 假设:结合多种检索方法(如向量检索和关键词检索)可以互补优势         | 0.83  | 3      | 需实现多路召回、融合排序，工程量适中            |
| CRAG                       | 假设:系统需要能够评估检索质量并在必要时寻找替代信息源            | 0.824 | 5      | 需实现检索质量评估、动态切换外部源（如Web），流程最复杂 |
